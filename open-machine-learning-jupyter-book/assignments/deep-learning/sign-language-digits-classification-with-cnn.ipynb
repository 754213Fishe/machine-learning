{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Sign Language Digits Classification with Cnn"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Introduction\n","\n","In this kernel, sign language digits images will be classified with Convolutional Neural Network. CNN model will be like this;\n","\n","conv => maxpool => dropout <br/>\n","conv => maxpool => dropout <br/>\n","conv => maxpool => dropout <br/> \n","flatten => dropout => Dense(relu) => Dense (softmax)\n","\n","Also we will use data augmentation to avoid overfitting. \n","\n","1. [Load Data and PreCheck](#1)\n","1. [Preparing Data](#2)\n","1. [Train Test Split](#3)\n","1. [Implemantation of CNN](#4)\n","    * [Data Augmentation with Keras API](#5)\n","    * [Model Implementation](6)\n","1. [Conclusion](#7)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load Data and PreCheck"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.metrics import confusion_matrix\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load data from numpy file"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["\n","X = np.load('../../assets/data/sign-language-digits-classification-with-cnn/X.npy')\n","y = np.load('../../assets/data/sign-language-digits-classification-with-cnn/Y.npy')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# reshape X\n","X = X.reshape(-1,64,64,1)\n","\n","print(\"X Shape:\",X.shape)\n","print(\"Y Shape:\",y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(20,6))\n","\n","for i,j in enumerate([0,205,411,617,823,1030,1237,1444,1650,1858]):\n","    plt.subplot(2,5,i+1)\n","    plt.subplots_adjust(top = 2, bottom = 1)\n","    plt.imshow(X[j].reshape(64,64))\n","    plt.title(np.argmax(y[j]))\n","    plt.axis('off')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* As you can see, labels and images don't match correctly. So first of all we will re-organize them.\n","* Image size is 64x64\n","* There are 2062 images in dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["list_y = []\n","list_y = [np.where(i == 1)[0][0] for i in y]\n","count = pd.Series(list_y).value_counts()\n","print(count)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize = (10,5))\n","sns.countplot(np.array(list_y))\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* We have a balanced dataset."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Preparing Data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We will re-organize data to match labels and images correctly.\n","* 204-409   => 0\n","* 822-1028  => 1\n","* 1649-1855 => 2\n","* 1443-1649 => 3\n","* 1236-1443 => 4\n","* 1855-2062 => 5\n","* 615-822   => 6\n","* 409-615   => 7\n","* 1028-1236 => 8\n","* 0-204     => 9"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_organized = np.concatenate((X[204:409,:],\n","                              X[822:1028,:],\n","                              X[1649:1855,:],\n","                              X[1443:1649,:],\n","                              X[1236:1443,:],\n","                              X[1855:2062,:],\n","                              X[615:822,:],\n","                              X[409:615,:],\n","                              X[1028:1236,:],\n","                              X[0:204,:]),axis = 0)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(20,6))\n","\n","for i,j in enumerate([0,205,411,617,823,1030,1237,1444,1650,1858]):\n","    plt.subplot(2,5,i+1)\n","    plt.subplots_adjust(top = 2, bottom = 1)\n","    plt.imshow(X_organized[j].reshape(64,64))\n","    plt.title(np.argmax(y[j]))\n","    plt.axis('off')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* Now labels and images are matched correctly."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id='3'></a>\n","# Train Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","x_train,x_test,y_train,y_test = train_test_split(X_organized,y,test_size = 0.2,random_state = 42)\n","\n","print(\"x_train shape:\",x_train.shape)\n","print(\"x_test shape:\",x_test.shape)\n","print(\"y_train shape:\",y_train.shape)\n","print(\"y_test shape:\",y_test.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* Now our test and train datasets are ready. We can start to create CNN model."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<a id='4'></a>\n","# Implementation of CNN"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Data Augmentation With Keras API\n","\n","Data augmentation is a technique which generates new training samples without changing labels of images. To generate new samples, some features of images are changed like brightness, rotation or zoom level. To apply it, ImageDataGenerator class is used in KERAS API. This class refers parameters and changes images. After complete the changing process, it returns new samples. This is important! ImageDataGenerator returns only new images. It means that out training dataset consists of different from original dataset. It provides more generalizaton for model anf of course it is desirable.\n","\n","So, in implementation of CNN part, we will use data augmentation and we will change rotation and zoom level of images. we chose these parameters with a simple logic. Think of test data that we might encounter in real life. we don't always hold our hand at 90 degrees. So it is quite possible that we have a rotational change when using sign language. Likewise, the zoom level of the photo to be taken may also change. So we thought we could train my model better by creating a more general data set with these two parameters.  Let's take a closer look at these parameters.\n","\n","* **rotation_range:** Rotation augmentation randomly rotates the image clockwise by a given number between 0 and 360.\n","* **zoom_range:** The percentage of the zoom can be a single float or a range as an array or tuple. If a float is specified, then the range for the zoom will be [1-value, 1+value].\n","\n","We will apply data augmentation with this parameters.\n","* rotation = 45\n","* zoom_range = 0.5\n","\n","Before continue to CNN implementation, let's look some samples to see effects of data augmentation on dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def show_new_samples(new_images):\n","    plt.figure(figsize=(20,6))\n","    for i in range(10):\n","        plt.subplot(2,5,i+1)\n","        image = new_images.next()\n","        plt.imshow(image[0].reshape(64,64))\n","        plt.axis('off')\n","    \n","    plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Changin zoom level"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["datagen = ImageDataGenerator(zoom_range = 0.5)\n","new_images = datagen.flow(x_train,batch_size = 250)\n","show_new_samples(new_images)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Changing rotaion"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["datagen = ImageDataGenerator(rotation_range = 45)\n","new_images = datagen.flow(x_train,batch_size = 250)\n","show_new_samples(new_images)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Changing rotaion, zoom"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["datagen = ImageDataGenerator(zoom_range = 0.5,rotation_range = 45)\n","new_images = datagen.flow(x_train,batch_size = 1)\n","show_new_samples(new_images)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Model Implementation"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Load libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import Dense, Dropout, MaxPool2D, Conv2D, Flatten\n","from keras.optimizers import Adam\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = Sequential()\n","\n","model.add(Conv2D(filters = 32, kernel_size = (9,9),padding = 'Same', activation ='relu', input_shape = (64,64,1)))\n","model.add(MaxPool2D(pool_size=(5,5)))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(filters = 64, kernel_size = (7,7),padding = 'Same', activation ='relu'))\n","model.add(MaxPool2D(pool_size=(4,4), strides=(3,3)))\n","model.add(Dropout(0.2))\n","\n","model.add(Conv2D(filters = 128 , kernel_size = (5,5),padding = 'Same',activation ='relu'))\n","model.add(MaxPool2D(pool_size=(3,3), strides=(2,2)))\n","model.add(Dropout(0.2))\n","\n","model.add(Flatten())\n","model.add(Dropout(0.2))\n","model.add(Dense(256, activation = \"relu\"))\n","model.add(Dense(10, activation='softmax'))\n","\n","optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n","\n","model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","datagen = ImageDataGenerator(zoom_range = 0.5,rotation_range = 45)\n","datagen.fit(x_train)\n","\n","history = model.fit(datagen.flow(x_train,y_train, batch_size=250),epochs = 100, validation_data = (x_test,y_test))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Conclusion"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize = (10,5))\n","plt.plot(history.history['val_loss'], color='b', label=\"validation loss\")\n","plt.title(\"Test Loss\")\n","plt.xlabel(\"Number of Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_predict = model.predict(x_test)\n","y_predict_classes = np.argmax(y_predict,axis = 1) \n","y_true = np.argmax(y_test,axis = 1) \n","confusion_mtx = confusion_matrix(y_true, y_predict_classes) \n","plt.figure(figsize = (10,10))\n","sns.heatmap(confusion_mtx, annot=True,fmt= '.1f')\n","plt.xlabel(\"Predicted Label\")\n","plt.ylabel(\"True Label\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Acknowledgments\n","\n","Thanks to [Görkem Günay](https://www.kaggle.com/gorkemgunay) for creating [sign-language-digits-classification-with-cnn](https://www.kaggle.com/code/gorkemgunay/sign-language-digits-classification-with-cnn). It inspires the majority of the content in this chapter."]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":4}
